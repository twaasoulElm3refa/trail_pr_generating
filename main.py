from fastapi import FastAPI
#import mysql.connector
from connection_test import check_mysql_connection,fetch_press_releases ,update_press_release
import os
from dotenv import load_dotenv
#from fastapi.middleware.cors import CORSMiddleware
import uvicorn
#import asyncio
#from pydantic import BaseModel
import openai
#import faiss
#import numpy as np
#import json
#from sentence_transformers import SentenceTransformer


app = FastAPI()

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
host = os.getenv("DB_HOST")
port = os.getenv("DB_PORT")


def generate_article_based_on_topic(topic,context,lines_number,website):
   
    # Create the prompt for GPT
    prompt = f"""
ุฃูุช ุตุญูู ุนุฑุจู ูุญุชุฑู ูู ูุคุณุณุฉ ุฅุนูุงููุฉ ุจุงุฑุฒุฉุ ููุชุฎุตุต ูู ูุชุงุจุฉ ุงูุจูุงูุงุช ุงูุฅุฎุจุงุฑูุฉ ุจูุบุฉ ุนุฑุจูุฉ ูุตูุญุฉ ุชููู ุจุงูุดุงุก ุจูุงู ุตุญูู ููุงุจุฉ ุนููู ุญูุซ ุชุตูุบ ุงูุจูุงู ุจุตูุบุฉ "ุชุนูู ุดุฑูุฉ ..."ูููุณ "ุงุนููุช" ูุน ุงูุงูุชุฒุงู ุจุงูุจูุงูุงุช ูุงูุชูุงุตูู ุงูููููุญุฉ ุงููู ูุตูุงุบุชูุง ูู ุตูุฑู ุจูุงู ูุน ุงูุงูุชุฒุงู ุจุนุฏุฏ ุงูุงุณุทุฑ {lines_number} ูุนุชูุฏุง ูู ุงูุจูุงู ุนูู ุงูุจูุงูุงุช ุงููุฏุฎูู ูู ูู ุงููุณุชุฎุฏู ุงู ููุงูุน ุฑุณููู ุฐุงุช ูุตุงุฏุฑ ููุซูู ูุงุฆุฉ ุจุงูููุงุฆุฉ ูุน ุฐูุฑ ูู ุจุฏุงูู ุงูุจูุงู ุงูุนููุงู ุงูุฑุฆูุณู ู ุชุงุฑูุฎ ุงูููู ุญุณุจ ุงููุทู ุงูุนุฑุจู ุซู ูุญุชูู ุงูุจูุงู ุซู ูููุฉ 'ูููุญุฑุฑูู'  ุซู ุงูุญูู ุซู ูู ููุงูู ุงูุจูุงู ุจูุงูุงุช ุงูุชูุงุตู ูู ุชููููู ู ุงูููู ู ูุณุงุฆู ุงูุชูุงุตู ุงูุงุฌุชูุงุนู (ุงู ุฐูุฑุช ูู ุงูุชูููู ุงู ุงูุจูุงูุงุช ุงููุฏุฎูู ูู ุงููุณุชุฎุฏู) ุฏูู ุชุงููู ุงู ุชุนุฏูู ูุน ุชุฑู ูุณุงุญุชูุง ูุงุฑุบู ุงุฐุง ูู ูุชู ุชุญุฏูุฏูุง ูู ุงููุณุชุฎุฏู: {topic}.
    ุงุณุชุฎุฏู ุงููุนูููุงุช ุงูุชุงููุฉ ููููุฐุฌ ูููููุฉ ุตูุงุบู ุงููุจูุงู :
    {context}
    ู ุงูุฑุฌูุน ุงูู ูููุนูู ุงูููุฌูุฏ ูู  {website} ููุชุงุจู ุญูู ุนููู ูู ุฎุฏูุงุช ููุฏูููุง ุงูู ูู ูู 
    """  
   
    # Get response from OpenAI
    response  = openai.chat.completions.create(model="gpt-4o-mini",
                                               store=True,
                                               messages=[{"role": "user", "content": prompt}]
                                              )
    
    return response.choices[0].message.content.strip()

'''def generate_article_based_on_topic(topic, corpus, index,lines_number,website):

    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    # Find relevant documents based on the topic embedding
    topic_embedding = model.encode([topic])
    D, I = index.search(np.array(topic_embedding), 3)  # Get top 3 related documents

    # Retrieve the content for those documents
    context = "\n".join([corpus[i]["content"] for i in I[0]])

    # Create the prompt for GPT
    prompt = f"""
ุฃูุช ุตุญูู ุนุฑุจู ูุญุชุฑู ูู ูุคุณุณุฉ ุฅุนูุงููุฉ ุจุงุฑุฒุฉุ ููุชุฎุตุต ูู ูุชุงุจุฉ ุงูุจูุงูุงุช ุงูุฅุฎุจุงุฑูุฉ ุจูุบุฉ ุนุฑุจูุฉ ูุตูุญุฉ ูุน ุงูุงูุชุฒุงู ุจุงูุจูุงูุงุช ูุงูุชูุงุตูู ุงูููููุญุฉ ุงููู ูุตูุงุบุชูุง ูู ุตูุฑู ุจูุงู ูุน ุงูุงูุชุฒุงู ุจุนุฏุฏ ุงูุงุณุทุฑ {lines_number} ูุนุชูุฏุง ูู ุงูุจูุงู ุนูู ุงูุจูุงูุงุช ุงููุฏุฎูู ูู ูู ุงููุณุชุฎุฏู ุงู ููุงูุน ุฑุณููู ุฐุงุช ูุตุงุฏุฑ ููุซูู ูุงุฆุฉ ุจุงูููุงุฆุฉ ูุน ุฐูุฑ ูู ุจุฏุงูู ุงูุจูุงู ุงูุนููุงู ุงูุฑุฆูุณู ู ุชุงุฑูุฎ ุงูููู ุญุณุจ ุงููุทู ุงูุนุฑุจู ุซู ูุญุชูู ุงูุจูุงู ุซู ูููุฉ 'ูููุญุฑุฑูู'  ุซู ุงูุญูู ุซู ูู ููุงูู ุงูุจูุงู ุจูุงูุงุช ุงูุชูุงุตู ูู ุชููููู ู ุงูููู ู ูุณุงุฆู ุงูุชูุงุตู ุงูุงุฌุชูุงุนู (ุงู ุฐูุฑุช ูู ุงูุชูููู ุงู ุงูุจูุงูุงุช ุงููุฏุฎูู ูู ุงููุณุชุฎุฏู) ุฏูู ุชุงููู ุงู ุชุนุฏูู ูุน ุชุฑู ูุณุงุญุชูุง ูุงุฑุบู ุงุฐุง ูู ูุชู ุชุญุฏูุฏูุง ูู ุงููุณุชุฎุฏู: {topic}.
    ุงุณุชุฎุฏู ุงููุนูููุงุช ุงูุชุงููุฉ ููููุฐุฌ ูููููุฉ ุตูุงุบู ุงููุจูุงู :
    {context}
    ู ุงูุฑุฌูุน ุงูู ูููุนูู ุงูููุฌูุฏ ูู  {website} ููุชุงุจู ุญูู ุนููู ูู ุฎุฏูุงุช ููุฏูููุง ุงูู ูู ูู 
    """

    # Get response from OpenAI
    response  = openai.chat.completions.create(
      model="gpt-4o-mini",
      store=True,
      messages=[{"role": "user", "content": prompt}]
        )
    
    return response.choices[0].message.content.strip()'''


'''# โ 1. ุฅุนุฏุงุฏ CORS Middleware (ุงุฎุชูุงุฑู ููู ููู ูู ุนูุฏู Frontend ุฎุงุฑุฌู)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # โ ุฃู ุถุน ุฏููููุงุช ูุญุฏุฏุฉ ูุซู ["https://yourfrontend.com"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# โ 2. Middleware ูุชุณุฌูู ูู ุทูุจ ูุฑุฏ
@app.middleware("http")
async def log_requests(request: Request, call_next):
    print(f"๐ฅ Request: {request.method} {request.url}")
    response = await call_next(request)
    print(f"๐ค Response status: {response.status_code}")
    return response'''


@app.get("/{user_id}")
async def root(user_id: str):
    connection =check_mysql_connection()
    #cursor = connection.cursor(dictionary=True)
    if connection is None:
        print("Failed to establish database connection")  # ูู ุชุธูุฑ ุฅุฐุง ุงูุงุชุตุงู ูุงุฌุญ
    else:
        user_session_id = user_id
        all_release = fetch_press_releases(user_session_id)
        if not all_release:
            return {"error": "ูุง ุชูุฌุฏ ูุชุงุฆุฌ ูู all_release"}
        release = all_release[-1]
      

       ''' with open('filtered_corpus.json', 'r', encoding='utf-8') as json_file:
            corpus = json.load(json_file)
        index = faiss.read_index("my_index.index")'''
    
        # Prepare the Arabic prompt
        topic = f"ุงูุชุจ ุจูุงู ููุดุฑูุฉ {release['organization_name']} ุญูุซ ูุญุชูู ุงูุจูุงู ุนู {release['about_press']} ูุจูุงูุงุช ุงูุชูุงุตู {release['organization_phone'],release['organization_email'],release['organization_website']} ุจุชุงุฑูุฎ {release['press_date']} ูุงุฐูุฑ ุญูู ุงูุดุฑูู ูู ุงูููุงูู{release['about_organization']} ููููู ุนุฏุฏ ุงูุงุณุทุฑ {release['press_lines_number']}"
        context = f"""ุชูุดู ุฃุญุฏุซ ุงูุฃุจุญุงุซ ุงูุชู ุฃุฌุฑุชูุง ูุงุณู ูุฏููุณูุชู ุฃู ุฃูุงูู ุงูุนูู ุงูุชูููุฉ ูุง ุชุฒุงู ุชูุญู ุจุฃููุงุท ุงูุนูู ุงูุฌุฏูุฏุฉ
    ูููุฐุฌ ุจูุงู ุตุญูู ูุฃู ููุงุณุจุฉ
    ูููู ุชุฎุตูุต ูููุฐุฌ ุจูุงู ุตุญูู ุฃุณุงุณู ูุฃู ุฅุนูุงู ุชูุฑูุจูุง. ุงุจุฏุฃ ุจุงุณุชุฎุฏุงู ุงููููุฐุฌ ุฃุฏูุงู. ุฃุซูุงุก ุงููุชุงุจุฉุ ุงููุฃ ุงููุต ุจูู ููุณููุ ูููู ูุง ุชูุฏุฑุฌ ุฃุณูุงุก ุงูุฃูุณุงูุ ููู ููุชูุจุฉ ุจุฎุท ูุงุฆู.
    [ุดุนุงุฑ ุงูุดุฑูุฉ]
    ูููุดุฑ ุงูููุฑู
    ุงูุนููุงู ุงูุฑุฆูุณู
    [ุนููุงู ุฌุฐุงุจ ูุบูู ุจุงููุนูููุงุชุ ูููุถู ุฃูุง ูุชุฌุงูุฒ 100 ุญุฑู.]
    ุนููุงู ูุฑุนู
    [ุงุฎุชูุงุฑู: ุนููุงู ุซุงููู ููุฌุฒ ูููุฑ ูุนูููุงุช ุฅุถุงููุฉ.]
    ุฎุท ุงูุชุงุฑูุฎ
    [ุงููุฏููุฉุ ุงูููุงูุฉุ ุงูุชุงุฑูุฎ] โ [ููุฏูุฉ ููุฅุนูุงู.]
    ููุฑุฉ ุฑุฆูุณูุฉ
    [ูุฎูุต ุงูุฃุณุฆูุฉ ุงูุฎูุณุฉ: ููุ ูุงุฐุงุ ูุชูุ ุฃููุ ูููุงุฐุง. ูุฏูู ููุญุฉู ููุฌุฒุฉู ุนู ุงูุฅุนูุงู.]
    ูุญุชูู ุงูุฌุณู
    
    [ุงุดุฑุญ ุงูููุฑุฉ ุงูุงูุชุชุงุญูุฉ ุจูุฒูุฏ ูู ุงูุชูุตูู ุงูููุงุท ุงูุฑุฆูุณูุฉ ูุชูุงุตูู ุงูุฎูููุฉ ูุฃู ุณูุงู ุฐู ุตูุฉ. ุชุฃูุฏ ูู ุฃู ูุฐุง ุงููุณู ููุธู ุฌูุฏูุง ูุฌุฐุงุจ.]	
    ููุชุจุณ
    [ุฃุฏุฑุฌ ุงูุชุจุงุณูุง ูู ุดุฎุตูุฉ ุฑุฆูุณูุฉ ูู ุงูููุธูุฉ. ููุฑุฌู ููุงุญุธุฉ ุฃูู ููููู ุฃูุถูุง ูุดุฑ ุงูุงูุชุจุงุณุงุช ูู ุฌููุน ุฃูุญุงุก ุตูุบุฉ ุงูุจูุงู ุงูุตุญูู.]
    ูุนูููุงุช ุฏุงุนูุฉ
    [ูู ุจุชูููุฑ ุฅุญุตุงุฆูุงุช ูุงุถุญุฉ ูููุฌุฒุฉ ุฃู ุงุชุฌุงูุงุช ุฃู ูุนูููุงุช ุฃุฎุฑู ุชุฏุนู ุฅุนูุงูู.]
    ุฏุนูุฉ ุฅูู ุงูุนูู
    ุฃุฎุจุฑ ุงููุงุฑุฆ ุจูุง ุชุฑูุฏ ููู ูุนูู ุชุงูููุง. ุงุฌุนู ุฏุนูุชู ูุงุถุญุฉ ููููุนุฉ.
    ูุงูุจ ูููุฐุฌู
    ูุฏูู ูุนูููุงุช ุฃุณุงุณูุฉ ุนู ูุคุณุณุชูุ ุจูุง ูู ุฐูู ุฑุณุงูุชูุง ูุชุงุฑูุฎูุง ูุฃูู ุฅูุฌุงุฒุงุชูุง. ุงุฌุนููุง ููุฌุฒุฉ ูููุงุณุจุฉ ูุฌูููุฑู. 
    ูุนูููุงุช ุงูุงุชุตุงู
    [ุงุณู]
    [ุนููุงู]
    [ุงุณู ุงูุดุฑูุฉ]
    [ุฑูู ุงูุชููููู]
    [ุนููุงู ุงูุจุฑูุฏ ุงูุฅููุชุฑููู]
    [ูููุน ุฅููุชุฑููู]
    [ููุงุจุถ ูุณุงุฆู ุงูุชูุงุตู ุงูุงุฌุชูุงุนู]
    ุชุนุฒูุฒ ุงููุตูู ูุงููุชุงุฆุฌ ูุน ุฎุจุฑุงุก ุงูุจูุงูุงุช ุงูุตุญููุฉ
    ูุจู ุฅุชูุงู ุชูุณูู ุงูุจูุงู ุงูุตุญููุ ูููู ููููุงุฐุฌ ุฃู ุชุณุงุนุฏ ูู ุถูุงู ุชูุธูู ุฅุนูุงูุงุชู ูุงุญุชุฑุงููุชูุง ูุชูุณูููุง ุจุดูู ุตุญูุญ. ููู ุงูุชุฑููุฌ ูุจูุงูู ุงูุตุญูู ูุถูุงู ูุตููู ุฅูู ุงูุฌูููุฑ ุงูููุงุณุจ ูู ุงูููุช ุงูููุงุณุจ ููุนุฏู ุฌุฒุกูุง ููููุง ุขุฎุฑ ูู ุนูู ูุชุฎุตุตู ุงูุนูุงูุงุช ุงูุนุงูุฉ. 
"""
        article = generate_article_based_on_topic(topic,context,release['press_lines_number'],release['organization_website'])
        
       # article = generate_article_based_on_topic(topic, corpus, index,release['press_lines_number'],release['organization_website'])
        
        print(article)
    
        update_data= update_press_release(release['user_id'], release['organization_name'], article)
        print("update_data",update_data)

        
        user = release['user_id'] 
        organization_name = release['organization_name']

        saved_data = update_press_release(user, organization_name, article)
        #print("Processing started...")
        #await asyncio.sleep(5)  # simulate long task
        #print("Processing finished.")
        
        connection.commit()
        connection.close()

    return {"last release": release , "data_condation": saved_data}

if __name__ == "__main__":              
    uvicorn.run(app, host=host, port=port)

